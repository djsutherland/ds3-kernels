{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\DeclareMathOperator*{\\argmin}{argmin}\n",
    "\\DeclareMathOperator*{\\E}{\\mathbb E}\n",
    "\\newcommand{\\R}{\\mathbb R}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- SOLUTION CELL -->\n",
    "<h2 style=\"color: red\">This is the solutions file!</h2>\n",
    "\n",
    "<span style=\"color: red\">We strongly recommend not looking at this file, which contains the solutions to all the exercises, until after the practical is over. Use [`practical.ipynb`](practical.ipynb) instead.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SOLUTION CELL\n",
    "# This is put straight into practical.ipynb so it renders untrusted...\n",
    "from IPython.display import display, Markdown\n",
    "with open('README-setup.md') as f:\n",
    "    display(Markdown(f.read()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='notebook')\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "# from tqdm import tqdm  # if you're in JupyterLab/etc and this doesn't work well\n",
    "\n",
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from ds3_support import as_tensors, plot_confusion_matrix, LazyKernel\n",
    "\n",
    "# download some datasets\n",
    "torchvision.datasets.MNIST(root='data', download=True)\n",
    "torchvision.datasets.Omniglot(root='data', download=True)\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just checking that tqdm works okay; feel free to interrupt or skip this cell.\n",
    "# If it doesn't work, then switch to the \"from tqdm import tqdm\" line above.\n",
    "import time\n",
    "print(\"\")\n",
    "for _ in tqdm(range(20)):\n",
    "    time.sleep(.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge regression\n",
    "Okay, time to get going.\n",
    "\n",
    "We're going to start with implementing kernel ridge regression. First, here's a toy dataset to test your code on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION CELL\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "\n",
    "def make_toy(n_pts, dist_seed=17, samp_seed=12):\n",
    "    drs = np.random.RandomState(seed=dist_seed)\n",
    "    inducing = drs.uniform(0, 1, size=50)\n",
    "    w = drs.normal(size=inducing.shape[0])\n",
    "    gamma = 1 / (2 * .05**2)\n",
    "    print(f\"||f||_H^2: {w @ rbf_kernel(inducing[:, None], gamma=gamma) @ w :.3}\")\n",
    "    \n",
    "    srs = np.random.RandomState(seed=samp_seed)\n",
    "    X = srs.uniform(0, 1, size=n_pts)\n",
    "    ymean = rbf_kernel(X[:, None], inducing[:, None], gamma=gamma) @ w\n",
    "    y = ymean + srs.normal(scale=.5, size=ymean.shape)\n",
    "    return X[:, None].astype(np.float32), y.astype(np.float32)\n",
    "\n",
    "X, y = make_toy(500)\n",
    "np.savez('data/ridge-toy.npz', X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load('data/ridge-toy.npz') as f:\n",
    "    toy_X = f['X']\n",
    "    toy_y = f['y']\n",
    "toy_X_train, toy_X_test, toy_y_train, toy_y_test = model_selection.train_test_split(\n",
    "    toy_X, toy_y, train_size=200)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(toy_X_train[:, 0], toy_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data looks like it could be well-modeled by a Gaussian RBF kernel. We'll need a fairly small bandwidth. See the minimum a little above 0.15 and the maximum a little less than 0.25? The Gaussian kernel still has a fair amount of influnce one bandwidth away, so we want to make the bandwidth a little smaller than that; say 0.05. So, first let's implement the kernel.\n",
    "\n",
    "<sup>I totally eyeballed that like I said, and definitely didn't just generate the true function in the first place from an RBF function with that bandwidth....</sup>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, first, let's implement an RBF kernel first. I've put some helper infrastructure in the `LazyKernel` class (in [`ds3_support.kernels`](ds3_support/kernels.py)) that will be especially useful later; for now, it's just a way to organize computing it. Here's an example of how to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearKernel(LazyKernel):\n",
    "    def _compute(self, A, B):\n",
    "        return A @ B.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `_compute` method computes the kernel between two inputs `A` and `B`. (`.t()` is PyTorch for taking a transpose; `@` is the nifty Python 3.6+ syntax for matrix multiplication.)\n",
    "\n",
    "The `LazyKernel` base class lets us use this in various ways. First, to find the kernel from one set of points to another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = LinearKernel(toy_X_train, toy_X_test)\n",
    "print(K)\n",
    "K.XY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get the X-to-X (`XX`) and Y-to-Y (`YY`) kernel matrices from the same object (which are the result of `_compute(X, X)` and `_compute(Y, Y)`). These aren't computed until you need them, but then they're cached after you use them the first time; this is why it's a `LazyKernel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you only want the kernel matrix for a dataset to itself, you can just not pass the second argument. Then K.XY won't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearKernel(toy_X_train).XX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can pass `None`, which is a special value meaning \"use the first one.\" Then `XY` and so on will exist, but it knows to cache them appropriately.\n",
    "\n",
    "You can also pass three arguments; then there'll be `XZ`, etc. You can also access them with e.g. `K[0, 2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = LinearKernel(toy_X_train, None, toy_X_test)\n",
    "print(K)\n",
    "K.YZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's an example of a slightly more complex kernel class, with some parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialKernel(LazyKernel):\n",
    "    def __init__(self, X, *rest, degree=3, gamma=None, coef0=1):\n",
    "        super().__init__(X, *rest)\n",
    "        self.degree = degree\n",
    "        self.gamma = 1 / X.shape[1] if gamma is None else gamma\n",
    "        self.coef0 = coef0\n",
    "\n",
    "    def _compute(self, A, B):\n",
    "        XY = A @ B.t()\n",
    "        return (self.gamma * XY + self.coef0) ** self.degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You also totally don't need to do this \u2013\u00a0you definitely won't notice the difference on this scale of data \u2013 but if you want to cache some computation for each dataset, you can use the `_precompute` interface. You can return a list of cached information in `_precompute`, which then get passed to `_compute` as `_compute(A, *A_precomputed, B, *B_precomputed)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearAndSquareKernel(LazyKernel):\n",
    "    def _precompute(self, A):\n",
    "        return [A * A]\n",
    "    \n",
    "    def _compute(self, A, A_squared, B, B_squared):\n",
    "        return A @ B.t() + A_squared @ B_squared.t()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the Gaussian RBF kernel is\n",
    "$$k(x, y) = \\exp\\left( -\\frac{1}{2 \\sigma^2} \\lVert x - y \\rVert^2 \\right).$$\n",
    "Go ahead and implement that here. It might be helpful to recall that\n",
    "$$\\lVert x - y \\rVert^2 = \\lVert x \\rVert^2 + \\lVert y \\rVert^2 - 2 x^T y.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFKernel(LazyKernel):\n",
    "    def __init__(self, *parts, sigma=1):\n",
    "        super().__init__(*parts)\n",
    "        self.sigma = sigma\n",
    "    \n",
    "    # TODO: implement _compute (maybe with _precompute)\n",
    "    def _precompute(self, A):                                            # SOLUTION\n",
    "        # Squared norms of each data point                               # SOLUTION\n",
    "        return [torch.einsum(\"ij,ij->i\", A, A)]                          # SOLUTION\n",
    "                                                                         # SOLUTION\n",
    "    def _compute(self, A, A_sqnorms, B, B_sqnorms):                      # SOLUTION\n",
    "        D2 = A_sqnorms[:, None] + B_sqnorms[None, :] - 2 * (A @ B.t())   # SOLUTION\n",
    "        return torch.exp(D2 / (-2 * self.sigma ** 2))                    # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check your implementation against scikit-learn's implementation (but it doesn't work in PyTorch, so don't just use it directly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.random.lognormal()\n",
    "K = RBFKernel(toy_X_train, toy_X_test, sigma=sigma)\n",
    "\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "gamma = 1 / (2 * sigma**2)  # sklearn uses this parameterization\n",
    "assert np.allclose(K.XX.numpy(), rbf_kernel(toy_X_train, gamma=gamma))\n",
    "assert np.allclose(K.XY.numpy(), rbf_kernel(toy_X_train, toy_X_test, gamma=gamma))\n",
    "assert np.allclose(K.YY.numpy(), rbf_kernel(toy_X_test, gamma=gamma))\n",
    "\n",
    "del rbf_kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing ridge regression\n",
    "\n",
    "Okay, now we can compute all kinds of kernels; let's actually use them for something. First, let's implement ridge regression. Remember that ridge regression is\n",
    "$$\n",
    "  \\min_{f \\in \\mathcal{H}} \\frac{1}{n} \\sum_{i=1}^n \\lVert f(X_i) - y_i \\rVert^2 + \\frac12 \\lambda \\lVert f \\rVert_{\\mathcal{H}}^2 \n",
    ".$$\n",
    "The representer theorem tells us that $f(x) = \\sum_{i=1}^n \\alpha_i k(X_i, x)$,\n",
    "and then some calculus gives us\n",
    "$$\\alpha = (K + n \\lambda I)^{-1} y, \\tag{*}$$\n",
    "where $K_{ij} = k(X_i, X_j)$.\n",
    "\n",
    "There's also one more wrinkle: we're going to need to compute ridge regression for multiple outputs $y$ at once with the same $X$s. This just means solving the linear system for more than one $y$ at once; most software, including PyTorch, supports this built-in.\n",
    "\n",
    "To implement $\\textrm{(*)}$, there are (at least) two approaches.\n",
    "\n",
    "- [`torch.solve`](https://pytorch.org/docs/stable/torch.html#torch.solve) is a general-purpose matrix solver, which uses an [LU decomposition](https://en.wikipedia.org/wiki/LU_decomposition). This doesn't exploit the special structure of kernel matrices (namely that they're [positive-definite](https://en.wikipedia.org/wiki/Definiteness_of_a_matrix)).\n",
    "\n",
    "- You could also use a [Cholesky factorization](https://en.wikipedia.org/wiki/Cholesky_factorization), which is the standard approach for positive-definite matrices, and will be somewhat faster. You could implement this with [`torch.cholesky`](https://pytorch.org/docs/stable/torch.html#torch.cholesky) and [`torch.cholesky_solve`](https://pytorch.org/docs/stable/torch.html#torch.cholesky_solve) \u2013\u00a0but unfortunately PyTorch hasn't implemented derivatives through `cholesky_solve` yet, and we're going to need that later. You can use [`torch.triangular_solve`](https://pytorch.org/docs/stable/torch.html#torch.triangular_solve) instead; Cholesky gives us $L$ such that $K + n \\lambda I = L L^T$, so you'll want $\\alpha = (L L^T)^{-1} y = L^{-T} (L^{-1} y)$. (Make sure to pass `upper=False` to `triangular_solve`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelRidgeRegression:\n",
    "    def __init__(\n",
    "        self,\n",
    "        reg_wt=1,\n",
    "        solver='cholesky',  # SOLUTION\n",
    "    ):\n",
    "        \"\"\"\n",
    "        reg_wt: The regularization weight lambda.\n",
    "        \"\"\"\n",
    "        self.reg_wt = reg_wt\n",
    "        self.solver = solver  # SOLUTION\n",
    "    \n",
    "    def fit(self, K_XX, y):\n",
    "        \"\"\"\n",
    "        Fit the ridge regression:\n",
    "        \n",
    "          K_XX: The training kernel matrix, of shape [n_train, n_train].\n",
    "          y: The training labels, of shape [n_train] or [n_train, n_labels].        \n",
    "        \"\"\"\n",
    "        K_XX, y = as_tensors(K_XX, y)\n",
    "        \n",
    "        assert len(K_XX.shape) == 2\n",
    "        self.n_train_ = K_XX.shape[0]\n",
    "        \n",
    "        if len(y.shape) == 1:\n",
    "            self.n_labels_ = None\n",
    "            y = y[:, None]\n",
    "        else:\n",
    "            assert len(y.shape) == 2\n",
    "            self.n_labels_ = y.shape[1]\n",
    "\n",
    "        assert K_XX.shape[1] == y.shape[0] == self.n_train_\n",
    "        \n",
    "        # TODO: find the solution, and save it in self.alpha_\n",
    "        # If you set anything\n",
    "        to_inv = K_XX + self.reg_wt * torch.eye(K_XX.shape[0])          # SOLUTION\n",
    "        if self.solver == 'lu':                                         # SOLUTION\n",
    "            # the LU-based solution                                     # SOLUTION\n",
    "            self.alpha_ = torch.solve(y, to_inv)[0]                     # SOLUTION\n",
    "        elif self.solver == 'cholesky':                                 # SOLUTION\n",
    "            # the cholesky solution (default)                           # SOLUTION\n",
    "            L = torch.cholesky(to_inv, upper=False)                     # SOLUTION\n",
    "            inner = torch.triangular_solve(y, L, upper=False).solution  # SOLUTION\n",
    "            self.alpha_ = torch.triangular_solve(                       # SOLUTION\n",
    "                inner, L, upper=False, transpose=True).solution         # SOLUTION\n",
    "        else:                                                           # SOLUTION\n",
    "            raise ValueError(f\"unknown solver {self.solver!r}\")         # SOLUTION\n",
    "    \n",
    "    def predict(self, K_test):\n",
    "        \"\"\"\n",
    "        Predict the labels of a test set.\n",
    "        \n",
    "          K_test: The train-to-test kernel matrix, shape [n_train, n_test].\n",
    "        \n",
    "        Return: the vector of test predictions, shape [n_test].\n",
    "        \"\"\"\n",
    "        K_test = torch.as_tensor(K_test)\n",
    "        assert len(K_test.shape) == 2\n",
    "        assert K_test.shape[0] == self.n_train_\n",
    "        \n",
    "        # TODO: set preds to shape [n_test, n_labels]\n",
    "        preds = K_test.t() @ self.alpha_     # SOLUTION\n",
    "        \n",
    "        # return a vector if we were fit with a vector, matrix otherwise\n",
    "        return preds.squeeze(1) if self.n_labels_ is None else preds\n",
    "    \n",
    "    def mses(self, K_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes the mean squared error of each output for a test set.\n",
    "        \n",
    "          K_test: The train-to-test kernel matrix, shape [n_train, n_test].\n",
    "          y_test: The test labels, shape [n_train] or [n_train, n_labels]\n",
    "                  (agreeing with what was passed to fit()).\n",
    "                  \n",
    "        Returns a vector if y_test is 2d, or a scalar if not.\n",
    "        \"\"\"\n",
    "        preds = self.predict(K_test)\n",
    "        y_test = torch.as_tensor(y_test)\n",
    "        assert preds.shape == y_test.shape\n",
    "        return ((preds - y_test) ** 2).mean(0)\n",
    "    \n",
    "    def mse(self, K_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes the mean squared error across outputs for a test set.\n",
    "        \n",
    "          K_test: The train-to-test kernel matrix, shape [n_train, n_test].\n",
    "          y_test: The test labels, shape [n_train] or [n_train, n_labels]\n",
    "                  (agreeing with what was passed to fit()).\n",
    "                  \n",
    "        Returns a scalar.\n",
    "        \"\"\"\n",
    "        return self.mses(K_test, y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does it work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(krr, kernel_cls=None, plot=True,\n",
    "             X_train=None, y_train=None, X_test=None, y_test=None):\n",
    "    if X_train is None:\n",
    "        X_train = toy_X_train\n",
    "    if y_train is None:\n",
    "        y_train = toy_y_train\n",
    "    if X_test is None:\n",
    "        X_test = toy_X_test\n",
    "    if y_test is None:\n",
    "        y_test = toy_y_test\n",
    "    \n",
    "    plot_xs = np.linspace(0, 1, num=500)[:, None]\n",
    "    if kernel_cls is None:\n",
    "        kernel_cls = functools.partial(RBFKernel, sigma=0.05)\n",
    "    K = kernel_cls(X_train, X_test, plot_xs)\n",
    "\n",
    "    krr.fit(K.XX, y_train)\n",
    "    train_mse = krr.mse(K.XX, y_train).item()\n",
    "    test_mse = krr.mse(K.XY, y_test).item()\n",
    "    \n",
    "    if plot:\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.scatter(X_train[:, 0], y_train)\n",
    "        ax.plot(plot_xs, krr.predict(K.XZ).numpy(), lw=4, color='r')\n",
    "        ax.set_title(f\"Train MSE: {train_mse:.2} / Test MSE: {test_mse:.2}\")\n",
    "    else:\n",
    "        return train_mse, test_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.1))\n",
    "plt.savefig('figs/toy-krr-eval.png'); plt.close()  # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what my solution looks like:\n",
    "![hi](figs/toy-krr-eval.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION CELL\n",
    "# Check that the LU solve also works; should be almost identical.\n",
    "evaluate(KernelRidgeRegression(reg_wt=.1, solver='lu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choice of $\\lambda$\n",
    "For this problem, we want a pretty small $\\lambda$, just enough to make it work, since the amount of inherent noise in the problem is fairly small. To check this, let's just try a bunch of different $\\lambda$s.\n",
    "\n",
    "(Note that the Cholesky solution is likely to crash with small $\\lambda$ before the `torch.solve` solution would, because \u2013 especially in the `float32` computation we're doing here \u2013\u00a0$K + n \\lambda I$ will appear singular. My results image below used the `torch.solve` version.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: What do you think will happen visually when you change $\\lambda$? Try a few different numbers for `reg_wt`, including increasing it really high (like `1000`), and see if it matches your intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "train_mses = []\n",
    "test_mses = []\n",
    "for lam in lams:\n",
    "    krr = KernelRidgeRegression(reg_wt=lam)\n",
    "    krr.solver = 'lu'    # SOLUTION\n",
    "    try:\n",
    "        train, test = evaluate(krr, plot=False)\n",
    "    except RuntimeError as e:\n",
    "        print(f\"{lam}: {e}\")\n",
    "        train = test = np.nan\n",
    "    train_mses.append(train)\n",
    "    test_mses.append(test)\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(lams, train_mses, marker='o', label='train MSE')\n",
    "ax.plot(lams, test_mses, marker='o', label='test MSE')\n",
    "ax.legend()\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(r'$\\lambda$')\n",
    "fig.savefig('figs/toy-krr-lambda.png'); plt.close()  # SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My results, for reference, look like:\n",
    "![](figs/toy-krr-lambda.png)\n",
    "\n",
    "My Cholesky solution failed for $\\lambda < 10^{-3}$, so your plot might cut off the first two points. We can actually tell that the behavior for these small values of $\\lambda$ is numerical error, not overfitting: overfitting would increase the test error, but have the same or lower training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the kernel\n",
    "\n",
    "We can also see whether my guess at $\\sigma$ was really right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** First, what happens when you change $\\sigma$? Try some numbers, including much larger and much smaller ones, and see if it looks like what you expect to happen. See how this interacts with setting $\\lambda$ as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.01),\n",
    "         kernel_cls=functools.partial(RBFKernel, sigma=.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** What happens if you use `LinearKernel`? `PolynomialKernel`, with different `degree`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.1),\n",
    "         kernel_cls=functools.partial(LinearKernel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to `RBFKernel`, let's do a joint search over $\\lambda$ and $\\sigma$, since they'll interact with one another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lams = [1e-3, 1e-2, 1e-1, 1e0, 1e1]\n",
    "sigs = [.001, .01, .05, .1, .25, .5, 1]\n",
    "mses = np.full((len(lams), len(sigs), 2), np.nan)\n",
    "\n",
    "for lam_i, lam in enumerate(lams):\n",
    "    for sig_i, sig in enumerate(sigs):\n",
    "        krr = KernelRidgeRegression(reg_wt=lam)\n",
    "        krr.solver = 'lu'  # SOLUTION\n",
    "        try:\n",
    "            mses[lam_i, sig_i, :] = evaluate(\n",
    "                krr, functools.partial(RBFKernel, sigma=sig), plot=False)\n",
    "        except RuntimeError as e:\n",
    "            print(f\"{lam} {sig}: {e}\")\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 4), constrained_layout=True)\n",
    "\n",
    "norm = mpl.colors.LogNorm(vmin=np.nanmin(mses), vmax=np.nanmax(mses))\n",
    "\n",
    "ax1, ax2 = axes\n",
    "ax1.matshow(mses[:, :, 0], norm=norm)\n",
    "best1, best2 = np.unravel_index(np.argmin(mses[:, :, 0]), mses.shape[:2])\n",
    "ax1.scatter([best2], [best1], marker='o', color='c', s=100)\n",
    "ax1.set_title(f\"Train MSE: min {mses[best1, best2, 0]:.3}\")\n",
    "\n",
    "im = ax2.matshow(mses[:, :, 1], norm=norm)\n",
    "best1, best2 = np.unravel_index(np.argmin(mses[:, :, 1]), mses.shape[:2])\n",
    "ax2.scatter([best2], [best1], marker='o', color='c', s=100)\n",
    "ax2.set_title(f\"Test MSE: min {mses[best1, best2, 1]:.3}\")\n",
    "fig.colorbar(im)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.grid(False)\n",
    "    \n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.xaxis.set_ticklabels([''] + [f'{sig}' for sig in sigs])\n",
    "    ax.set_xlabel(r'$\\sigma$')\n",
    "    \n",
    "    ax.yaxis.set_major_locator(mpl.ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_ticklabels([''] + [f'{lam}' for lam in lams])\n",
    "    ax.set_ylabel(r'$\\lambda$')\n",
    "    \n",
    "fig.savefig('figs/toy-krr-sig-lambda.png');  # SOLUTION\n",
    "# If you get a RuntimeWarning due to nans, don't worry about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, my result looks like\n",
    "![](figs/toy-krr-sig-lambda.png)\n",
    "Smaller $\\sigma$ can get lower training error, but the best test error is definitely with $\\sigma = 0.05$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shifting `y`\n",
    "\n",
    "What do you think will happen if we fit with `y` replaced by `y + 100`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal fit, for comparison\n",
    "evaluate(KernelRidgeRegression(reg_wt=.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit with labels shifted upwards by 100\n",
    "evaluate(KernelRidgeRegression(reg_wt=.1),\n",
    "         y_train=toy_y_train + 100, y_test=toy_y_test + 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Some\n",
    "\n",
    "blank\n",
    "\n",
    "space\n",
    "\n",
    "for\n",
    "\n",
    "you\n",
    "\n",
    "to\n",
    "\n",
    "think\n",
    "\n",
    "and\n",
    "\n",
    "then\n",
    "\n",
    "run\n",
    "\n",
    "it\n",
    "\n",
    "and\n",
    "\n",
    "then\n",
    "\n",
    "maybe\n",
    "\n",
    "think\n",
    "\n",
    "some\n",
    "\n",
    "more\n",
    "\n",
    "before\n",
    "\n",
    "seeing\n",
    "\n",
    "the\n",
    "\n",
    "discussion.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size: 2em\">\ud83e\udd14</span>\n",
    "\n",
    "Remember that in traditional linear regression, you fit $y = w \\cdot x + b$. Here, we're using $y = w \\cdot \\varphi(x)$; no $+ b$. Unlike in traditional linear regression, the kernel can more-or-less account for it, but the weird thing at the end \u2013\u00a0and the overall downward trend \u2013\u00a0could be fixed by adding an offset.\n",
    "\n",
    "The easiest way to do that is to add an additional dimension to $\\varphi(x)$ that's just a constant $1$, so that the corresponding element of $w$ can be $b$. Since $k(x, y) = \\varphi(x) \\cdot \\varphi(y)$, this means that we just add 1 to the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBFKernelPlusOne(RBFKernel):\n",
    "    def _compute(self, *args):\n",
    "        return super()._compute(*args) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.1),\n",
    "         kernel_cls=functools.partial(RBFKernelPlusOne, sigma=.05),\n",
    "         y_train=toy_y_train + 100, y_test=toy_y_test + 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing to note: traditional ridge regression regularizes with $\\lambda \\lVert w \\rVert^2$, and leaves $b$ unregularized. This has nice properties like making the fit shift _exactly_ along with an offset $y$. By adding 1 to the kernel, though, ours will _slightly_ change with offsets, because we're also effectively regularizing with $\\lambda b^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(KernelRidgeRegression(reg_wt=.1),\n",
    "         kernel_cls=functools.partial(RBFKernelPlusOne, sigma=.05),\n",
    "         y_train=toy_y_train + 5000, y_test=toy_y_test + 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few ways to resolve this:\n",
    "\n",
    "1. Actually add an unregularized offset into the model and work it out properly.\n",
    "2. Mitigate the scaling by adding a large constant, instead of 1; if you add $c$, then the regularization is effectively $\\lambda {b^2}/{c^2}$.\n",
    "3. Just subtract the mean of `y_train` before passing it into the model, then add it on to predictions later.\n",
    "\n",
    "People normally do option 3 in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A harder problem\n",
    "\n",
    "Okay, that problem was too easy. Let's do something slighty more interesting.\n",
    "\n",
    "Not _too_ interesting, though; we'll start with the MNIST dataset of handwritten images, with the goal of identifying which digit an image is. (We're building up!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some utilities for pytorch datasets\n",
    "def pil_grid(X, **kwargs):\n",
    "    return torchvision.transforms.ToPILImage()(torchvision.utils.make_grid(X, **kwargs))\n",
    "\n",
    "def read(ds, batch_size=None, **kwargs):\n",
    "    if batch_size is None:\n",
    "        batch_size = len(ds)\n",
    "    return next(iter(torch.utils.data.DataLoader(ds, batch_size=batch_size, **kwargs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST(\n",
    "    root='data',\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just look at some data points\n",
    "X, y = read(mnist, batch_size=100, shuffle=True)\n",
    "pil_grid(X, nrow=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But this is a classification dataset, and we're doing ridge regression right now, you say!\n",
    "\n",
    "That's true. You'd probably do better to use an actual classification loss. But we're going to just do regression to \"one-hot\" labels, that is the label for an image of a handwritten 0 will be\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n",
    "\\end{bmatrix}\n",
    ".$$\n",
    "We're going to use our multi-output support for RidgeRegression that we implemented before to train 10 different regression models: one that predicts the degree of zero-ness of an image, one for the one-ness, etc.\n",
    "\n",
    "(This is sometimes called the [Brier score](https://en.wikipedia.org/wiki/Brier_score#Original_definition_by_Brier), and it is a [proper scoring rule](https://en.wikipedia.org/wiki/Scoring_rule#ProperScoringRules). So, yes, you could get better performance from other losses, but this one is at least well-posed.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST has 60,000 images. Even constructing a, say, 50,000 $\\times$ 50,000 matrix is too much, so we'll turn to the approximations in a bit. Let's try training on a random subset first, though, to (a) check that our multi-output implementation works, and (b) set a baseline to compare to for the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a subset of the data\n",
    "mnist_subtrain, mnist_subval, mnist_rest = torch.utils.data.random_split(\n",
    "    mnist, [5_000, 1_000, 54_000])\n",
    "\n",
    "train_X, train_y = read(mnist_subtrain)\n",
    "val_X, val_y = read(mnist_subval)\n",
    "\n",
    "# Xs are currently shape [n, 1, 28, 28]; flatten them into vectors\n",
    "train_X = train_X.reshape(-1, 28 * 28)\n",
    "val_X = val_X.reshape(-1, 28 * 28)\n",
    "\n",
    "# ys are integers, 0 or 7 or whatever; want one-hots\n",
    "train_y_onehot = torch.nn.functional.one_hot(train_y, num_classes=10).float()\n",
    "val_y_onehot = torch.nn.functional.one_hot(val_y, num_classes=10).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we're ready to try training on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = RBFKernelPlusOne(train_X, val_X)\n",
    "\n",
    "krr = KernelRidgeRegression(reg_wt=.1)\n",
    "krr.fit(K.XX, train_y_onehot)\n",
    "\n",
    "val_preds = krr.predict(K.XY)\n",
    "val_predmax = val_preds.argmax(1)\n",
    "\n",
    "plot_confusion_matrix(val_y, val_predmax, np.arange(10), rotation=0)\n",
    "print(sklearn.metrics.classification_report(val_y.numpy(), val_predmax.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yeah....that wasn't great. We forgot to set the kernel bandwidth.\n",
    "\n",
    "A usual heuristic to start with is the median distance between data points.\n",
    "\n",
    "**Exercise:** compute the median distance between training data points. You can either compute this yourself, or use predefined functions, whichever you'd prefer. If it's too slow to compute, you can subsample the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: find med_sigma\n",
    "med_sigma = torch.median(torch.pdist(train_X)).item() # SOLUTION\n",
    "med_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = RBFKernelPlusOne(train_X, val_X, sigma=med_sigma)\n",
    "\n",
    "krr = KernelRidgeRegression(reg_wt=.1)\n",
    "krr.fit(K.XX, train_y_onehot)\n",
    "\n",
    "val_preds = krr.predict(K.XY)\n",
    "val_predmax = val_preds.argmax(1)\n",
    "\n",
    "plot_confusion_matrix(val_y, val_predmax, np.arange(10), rotation=0)\n",
    "print(sklearn.metrics.classification_report(val_y.numpy(), val_predmax.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! I got 96% accuracy, which is pretty reasonable. (You can do better with a convnet, of course, but not bad for such a simple model.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these predictions aren't actually valid probabilities, which is slightly annoying:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(val_preds.numpy().ravel(), bins='auto', histtype='stepfilled');\n",
    "plt.axvline(0, color='r')\n",
    "plt.axvline(1, color='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But is the median really the best choice? And what about the arbitrary choice of regularization weight?\n",
    "\n",
    "We could do a grid search like before, but let's do something more fun: gradient descent!\n",
    "\n",
    "We want to find the derivative of the validation error with respect to $\\sigma$ and $\\lambda$. That is,\n",
    "$$\n",
    "\\nabla_{\\sigma\\lambda} \\frac{1}{n^\\text{val}} \\sum_{i=1}^{n^\\text{val}} \\lVert\n",
    "    \\hat{y}_{X_\\text{train},\\sigma,\\lambda}(X_i^\\text{val}) - y_i^\\text{val}\n",
    "\\rVert^2\n",
    ",$$\n",
    "where $\\hat{y}_{X_\\text{train},\\sigma,\\lambda}$ is the predictor trained with $X_\\text{train}$ using kernel bandwidth $\\sigma$ and regularization $\\lambda$.\n",
    "\n",
    "(Although $\\hat y$ fundamentally uses the square loss, we could conceivably use another \"outer\" loss. But since $\\hat y$ isn't a distribution, we can't use cross-entropy or similar losses, so square loss is a reasonable choice.)\n",
    "\n",
    "Because we have a PyTorch expression for the whole process of $\\hat{y}$, we can just take derivatives. We'll paramaterize with $\\log \\lambda$ and $\\log \\sigma$, though, to avoid invalid values (and because it's probably a better domain for each anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_lam = torch.tensor(np.log(0.01), requires_grad=True)\n",
    "log_sig = torch.tensor(np.log(med_sigma), requires_grad=True)\n",
    "opt = torch.optim.SGD([log_lam, log_sig], lr=1)\n",
    "\n",
    "trace = []\n",
    "\n",
    "with tqdm(range(1000)) as bar:\n",
    "    for i in bar:\n",
    "        opt.zero_grad()  # reset gradient state before computing things\n",
    "\n",
    "        # use a smaller subset of training data, to compute faster\n",
    "        tr_inds = np.random.choice(train_X.shape[0], size=500, replace=False)\n",
    "        val_inds = np.random.choice(val_X.shape[0], size=500, replace=False)\n",
    "        \n",
    "        # compute the loss on the validation set\n",
    "        lam = torch.exp(log_lam)\n",
    "        sig = torch.exp(log_sig)\n",
    "        krr = KernelRidgeRegression(reg_wt=lam)\n",
    "        K = RBFKernelPlusOne(train_X[tr_inds], val_X[val_inds], sigma=sig)\n",
    "        krr.fit(K.XX, train_y_onehot[tr_inds])\n",
    "        loss = krr.mse(K.XY, val_y_onehot[val_inds])\n",
    "\n",
    "        loss.backward()  # compute the gradients\n",
    "        opt.step()       # update lam / sig following the gradients\n",
    "        trace.append((i, lam.item(), sig.item(), loss.item()))\n",
    "        bar.set_postfix(lam=f\"{lam.item():.4}\", sig=f\"{sig.item():.4}\")\n",
    "\n",
    "fig, (a1, a2, a3) = plt.subplots(ncols=3, figsize=(16, 4))\n",
    "inds, lams, sigs, losses = np.asarray(trace).T\n",
    "\n",
    "a1.plot(inds, losses)\n",
    "a1.set_title(\"MSE\")\n",
    "\n",
    "a2.plot(inds, lams)\n",
    "a2.set_title(r\"$\\lambda$\")\n",
    "a2.set_yscale('log')\n",
    "\n",
    "a3.plot(inds, losses)\n",
    "a3.set_title(r\"$\\sigma$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it actually does better with a smaller bandwidth (and a smaller $\\lambda$).\n",
    "\n",
    "One caveat to this is that the optimal parameters will generally depend on $n$; here we're finding the best parameters for a fit on 500 training points, but you might want smaller $\\lambda$ and $\\sigma$ as $n$ grows.\n",
    "\n",
    "Since the loss landscape is surely nonconvex, it might be better to combine grid search and local gradient descent, starting from various locations. We could of course try other optimizers too. But this is good enough for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Did this optimization help the MSE that it's optimizing on a held-out test set (from `mnist_rest`) versus our heuristic guess before? What about the classification accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try other kernels than the Gaussian RBF on this data. One that might be interesting is\n",
    "$$\n",
    "k(x, y) = \\exp\\left( -\\frac12 \\left(\\frac{\\lVert x - y \\rVert}{\\ell}\\right)^\\beta \\right)\n",
    ".$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced kernel ridge regression: kernel approximation\n",
    "\n",
    "Because MNIST is too big to fit directly, we were just subsampling.\n",
    "\n",
    "In the lecture, we discussed two approximations for this setting:\n",
    "\n",
    "- _Nystr\u00f6m_, instead of finding $f(x) = \\sum_{i=1}^n \\alpha_i k(X_i, x)$,\n",
    "finds $f(x) = \\sum_{i=1}^m \\alpha_i k(\\tilde X_i, x)$.\n",
    "You can pick the $\\tilde X_i$ in various ways:\n",
    "uniformly,\n",
    "according to a $k$-means clustering on the original $X_i$,\n",
    "by approximate leverage scores,\n",
    "or more.\n",
    "You could even optimize the $\\tilde X_i$ with gradient descent if you wanted,\n",
    "since we know how to do that;\n",
    "that makes the model something like a classical RBF net.\n",
    "\n",
    "- _Random Fourier features_ find a linear function in the feature space $\\cos(\\omega_i^T x)$, $\\sin(\\omega_i^T x)$.\n",
    "\n",
    "**Exercise:** Implement and compare ridge regression with Nystr\u00f6m and random Fourier features to the full kernel ridge regression based on subsampled data we've been using so far. You'll probably want to implement a ridge regression class in the primal, then make subclasses to handle the different kinds of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced ridge regression: Meta-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot = Omniglot(root='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot[-1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(omniglot._characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(x.split('/')[0] for x in omniglot._characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot._characters[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omniglot._alphabets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
